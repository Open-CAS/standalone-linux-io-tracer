#
# Copyright(c) 2020 Intel Corporation
# SPDX-License-Identifier: BSD-3-Clause
#

from math import isclose
import pytest
from datetime import timedelta
from attotime import attotimedelta

from test_utils.size import Size, Unit
from test_utils.os_utils import Udev
from test_tools.fio.fio_param import ReadWrite, IoEngine
from test_tools.fio.fio import Fio
from test_tools.fio.fio_result import FioResult
from storage_devices.disk import DiskType, DiskTypeSet
from core.test_run import TestRun
from test_tools.disk_utils import Filesystem
from test_utils.os_utils import sync
from test_tools.fs_utils import (
    create_directory,
    create_file,
    move,
    remove,
    write_file,
    ls,
)
from api.iotrace_stats_parser import (
    DeviceTraceStatistics,
    DeviceStats,
    IOStatistics,
    TimeStat,
    SectorStat,
    ServiceStats,
    Percentiles,
    Metrics,
)
import time

mountpoint = "/mnt"
tolerance_threshold = 0.1
latency_tolerance_threshold = 10000


@pytest.mark.require_disk("traced_dev", DiskTypeSet([DiskType.optane, DiskType.nand]))
def test_trace_stats():
    """
        title: Test for generated statistics correctness
        description: |
          Generate workload usign fio and compare fio output with iotracer output.
        pass_criteria:
          - Output generated by iotracer matches with workload triggered with fio.
    """
    Udev.disable()
    iotrace = TestRun.plugins["iotrace"]

    dev = TestRun.disks["traced_dev"]

    with TestRun.group("Compare read stats"):
        fio_cmd = get_fio_cmd(dev)
        fio_cmd = fio_cmd.read_write(ReadWrite.randread)

        with TestRun.step("Start tracing"):
            iotrace.start_tracing([dev.system_path])
            fio_output = fio_cmd.run()[0]

        with TestRun.step("Stop tracing"):
            iotrace.stop_tracing()

            trace_path = iotrace.get_latest_trace_path()

            stats = DeviceTraceStatistics(
                iotrace.get_trace_statistics(
                    trace_path=trace_path, dev_path=dev.system_path
                )
            )

            read_stats = stats.read

        with TestRun.step("Compare names of tested device"):
            if len(fio_output.disks_name()) != 1:
                TestRun.LOGGER.error("Number of traced devices doesn't match!")

        if stats.device.name != fio_output.disks_name()[0]:
            TestRun.LOGGER.error("Names of devices doesn't match!")

        with TestRun.step("Compare read average bandwidth"):
            fio_bandwidth = fio_output.read_bandwidth_average().get_value()
            iotrace_bandwidth = read_stats.metrics.bandwidth.get_value()

            if not isclose(
                iotrace_bandwidth, fio_bandwidth, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio bandwidth and iotrace read bandwidth is out of "
                    f"acceptable threshold. Iotrace: {iotrace_bandwidth}, "
                    f"fio: {fio_bandwidth}"
                )

        with TestRun.step("Compare read workset"):
            fio_workset = fio_output.read_io().get_value()
            iotrace_workset = read_stats.metrics.workset.get_value()

            if not isclose(iotrace_workset, fio_workset, rel_tol=tolerance_threshold):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace read workset is out of "
                    f"acceptable threshold. Iotrace: {iotrace_workset}, "
                    f"fio: {fio_workset}"
                )

        with TestRun.step("Compare read IOPS"):
            fio_iops = fio_output.read_iops()
            iotrace_iops = read_stats.metrics.iops

            if not isclose(iotrace_iops, fio_iops, rel_tol=tolerance_threshold):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace read iops is out of "
                    f"acceptable threshold. Iotrace: {iotrace_iops}, "
                    f"fio: {fio_iops}"
                )

        with TestRun.step("Compare read latency"):
            fio_latency_avg = (
                fio_output.read_completion_latency_average().total_nanoseconds()
            )
            iotrace_latency_avg = read_stats.latency.average.total_nanoseconds()

            if not isclose(
                iotrace_latency_avg,
                fio_latency_avg,
                abs_tol=latency_tolerance_threshold,
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace read avarage latency is out of "
                    f"acceptable threshold. Iotrace: {iotrace_latency_avg}, "
                    f"fio: {fio_latency_avg}"
                )

            fio_latency_min = (
                fio_output.read_completion_latency_min().total_nanoseconds()
            )
            iotrace_latency_min = read_stats.latency.min.total_nanoseconds()

            if not isclose(
                iotrace_latency_min,
                fio_latency_min,
                abs_tol=latency_tolerance_threshold,
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace read min latency is out of "
                    f"acceptable threshold. Iotrace: {iotrace_latency_min}, "
                    f"fio: {fio_latency_min}"
                )

            fio_latency_max = (
                fio_output.read_completion_latency_max().total_nanoseconds()
            )
            iotrace_latency_max = read_stats.latency.max.total_nanoseconds()

            if not isclose(
                iotrace_latency_max,
                fio_latency_max,
                abs_tol=latency_tolerance_threshold,
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace read max latency is out of "
                    f"acceptable threshold. Iotrace: {iotrace_latency_max}, "
                    f"fio: {fio_latency_max}"
                )

        with TestRun.step("Compare read size"):
            fio_size = fio_output.read_io().get_value()
            iotrace_size = read_stats.size.total.get_value()

            if not isclose(iotrace_size, fio_size, rel_tol=tolerance_threshold):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace read size is out of "
                    f"acceptable threshold. Iotrace: {iotrace_size}, "
                    f"fio: {fio_size}"
                )

        with TestRun.step("Compare number of read requests"):
            fio_reqs = fio_output.read_requests_number()
            iotrace_reqs = read_stats.count

            if not isclose(iotrace_reqs, fio_reqs, rel_tol=tolerance_threshold):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace number of read reqs is out of "
                    f"acceptable threshold. Iotrace: {iotrace_reqs}, "
                    f"fio: {fio_reqs}"
                )

        with TestRun.step("Compare read latency percentiles"):
            fio_percentiles = fio_output.read_completion_latency_percentile()
            iotrace_percentiles = read_stats.latency.percentiles
            fio_90 = fio_percentiles["90.000000"]
            fio_99 = fio_percentiles["99.000000"]
            fio_99_9 = fio_percentiles["99.900000"]
            fio_99_99 = fio_percentiles["99.990000"]

            if not isclose(
                iotrace_percentiles.le90, fio_90, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace read 90 percentile is out of "
                    f"acceptable threshold. Iotrace: {iotrace_percentiles.le90}, "
                    f"fio: {fio_90}"
                )
            if not isclose(
                iotrace_percentiles.le99, fio_99, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace read 99 percentile is out of "
                    f"acceptable threshold. Iotrace: {iotrace_percentiles.le99}, "
                    f"fio: {fio_99}"
                )
            if not isclose(
                iotrace_percentiles.le99_90, fio_99_9, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace read 99.9 percentile is out of "
                    f"acceptable threshold. Iotrace: {iotrace_percentiles.le99_90}, "
                    f"fio: {fio_99_9}"
                )
            if not isclose(
                iotrace_percentiles.le99_99, fio_99_99, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace read 99.99 percentile is out of "
                    f"acceptable threshold. Iotrace: {iotrace_percentiles.le99_99}, "
                    f"fio: {fio_99_99}"
                )

        with TestRun.step("Compare number of errors"):
            fio_errors = fio_output.total_errors()
            iotrace_errors = read_stats.errors

            if not isclose(iotrace_errors, fio_errors, rel_tol=tolerance_threshold):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace errors is out of "
                    f"acceptable threshold. Iotrace: {iotrace_errors}, "
                    f"fio: {fio_errors}"
                )

    with TestRun.group("Compare write stats"):
        fio_cmd = get_fio_cmd(dev)
        fio_cmd = fio_cmd.read_write(ReadWrite.randwrite)

        with TestRun.step("Start tracing"):
            iotrace.start_tracing([dev.system_path])
            fio_output = fio_cmd.run()[0]

        with TestRun.step("Stop tracing"):
            iotrace.stop_tracing()

            trace_path = iotrace.get_latest_trace_path()

            stats = DeviceTraceStatistics(
                iotrace.get_trace_statistics(
                    trace_path=trace_path, dev_path=dev.system_path
                )
            )

            write_stats = stats.write

        with TestRun.step("Compare write average bandwidth"):
            fio_bandwidth = fio_output.write_bandwidth_average().get_value()
            iotrace_bandwidth = write_stats.metrics.bandwidth.get_value()

            if not isclose(
                iotrace_bandwidth, fio_bandwidth, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio bandwidth and iotrace write bandwidth is out of "
                    f"acceptable threshold. Iotrace: {iotrace_bandwidth}, "
                    f"fio: {fio_bandwidth}"
                )

        with TestRun.step("Compare number of requests"):
            fio_requests = fio_output.write_requests_number()
            iotrace_requests = write_stats.count

            if not isclose(iotrace_requests, fio_requests, rel_tol=tolerance_threshold):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace number of write reqs is out of "
                    f"acceptable threshold. Iotrace: {iotrace_bandwidth}, "
                    f"fio: {fio_bandwidth}"
                )

        with TestRun.step("Compare write workset"):
            fio_workset = fio_output.write_io().get_value()
            iotrace_workset = write_stats.metrics.workset.get_value()

            if not isclose(iotrace_workset, fio_workset, rel_tol=tolerance_threshold):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace write workset is out of "
                    f"acceptable threshold. Iotrace: {iotrace_workset}, "
                    f"fio: {fio_workset}"
                )

        with TestRun.step("Compare write IOPS"):
            fio_iops = fio_output.write_iops()
            iotrace_iops = write_stats.metrics.iops

            if not isclose(iotrace_iops, fio_iops, rel_tol=tolerance_threshold):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace write iops is out of "
                    f"acceptable threshold. Iotrace: {iotrace_bandwidth}, "
                    f"fio: {fio_bandwidth}"
                )

        with TestRun.step("Compare write latency"):
            fio_latency_avg = (
                fio_output.write_completion_latency_average().total_nanoseconds()
            )
            iotrace_latency_avg = write_stats.latency.average.total_nanoseconds()

            if not isclose(
                iotrace_latency_avg,
                fio_latency_avg,
                abs_tol=latency_tolerance_threshold,
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace write avarage latency is out of "
                    f"acceptable threshold. Iotrace: {iotrace_latency_avg}, "
                    f"fio: {fio_latency_avg}"
                )

            fio_latency_min = (
                fio_output.write_completion_latency_min().total_nanoseconds()
            )
            iotrace_latency_min = write_stats.latency.min.total_nanoseconds()

            if not isclose(
                iotrace_latency_min,
                fio_latency_min,
                abs_tol=latency_tolerance_threshold,
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace write min latency is out of "
                    f"acceptable threshold. Iotrace: {iotrace_latency_min}, "
                    f"fio: {fio_latency_min}"
                )

            fio_latency_max = (
                fio_output.write_completion_latency_max().total_nanoseconds()
            )
            iotrace_latency_max = write_stats.latency.max.total_nanoseconds()

            if not isclose(
                iotrace_latency_max,
                fio_latency_max,
                abs_tol=latency_tolerance_threshold,
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace write max latency is out of "
                    f"acceptable threshold. Iotrace: {iotrace_latency_max}, "
                    f"fio: {fio_latency_max}"
                )

        with TestRun.step("Compare write latency percentiles"):
            fio_percentiles = fio_output.write_completion_latency_percentile()
            iotrace_percentiles = write_stats.latency.percentiles
            fio_90 = fio_percentiles["90.000000"]
            fio_99 = fio_percentiles["99.000000"]
            fio_99_9 = fio_percentiles["99.900000"]
            fio_99_99 = fio_percentiles["99.990000"]

            if not isclose(
                iotrace_percentiles.le90, fio_90, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace write 90 percentile is out of "
                    f"acceptable threshold. Iotrace: {iotrace_percentiles.le90}, "
                    f"fio: {fio_90}"
                )
            if not isclose(
                iotrace_percentiles.le99, fio_99, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace write 99 percentile is out of "
                    f"acceptable threshold. Iotrace: {iotrace_percentiles.le99}, "
                    f"fio: {fio_99}"
                )
            if not isclose(
                iotrace_percentiles.le99_90, fio_99_9, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace write 99.9 percentile is out of "
                    f"acceptable threshold. Iotrace: {iotrace_percentiles.le99_90}, "
                    f"fio: {fio_99_9}"
                )
            if not isclose(
                iotrace_percentiles.le99_99, fio_99_99, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace write 99.99 percentile is out of "
                    f"acceptable threshold. Iotrace: {iotrace_percentiles.le99_99}, "
                    f"fio: {fio_99_99}"
                )

        with TestRun.step("Compare number of errors"):
            fio_errors = fio_output.total_errors()
            iotrace_errors = write_stats.errors

            if not isclose(iotrace_errors, fio_errors, rel_tol=tolerance_threshold):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace errors is out of "
                    f"acceptable threshold. Iotrace: {iotrace_errors}, "
                    f"fio: {fio_errors}"
                )

    with TestRun.group("Compare discard stats"):
        fio_cmd = get_fio_cmd(dev)
        fio_cmd = fio_cmd.read_write(ReadWrite.randtrim)

        with TestRun.step("Start tracing"):
            iotrace.start_tracing([dev.system_path])
            fio_output = fio_cmd.run()[0]

        with TestRun.step("Stop tracing"):
            iotrace.stop_tracing()

            trace_path = iotrace.get_latest_trace_path()

            stats = DeviceTraceStatistics(
                iotrace.get_trace_statistics(
                    trace_path=trace_path, dev_path=dev.system_path
                )
            )

            discard_stats = stats.discard

        with TestRun.step("Compare discard average bandwidth"):
            fio_bandwidth = fio_output.trim_bandwidth_average().get_value()
            iotrace_bandwidth = discard_stats.metrics.bandwidth.get_value()

            if not isclose(
                iotrace_bandwidth, fio_bandwidth, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio bandwidth and iotrace discard bandwidth is out of "
                    f"acceptable threshold. Iotrace: {iotrace_bandwidth}, "
                    f"fio: {fio_bandwidth}"
                )

        with TestRun.step("Compare discard workset"):
            fio_workset = fio_output.trim_io().get_value()
            iotrace_workset = discard_stats.metrics.workset.get_value()

            if not isclose(iotrace_workset, fio_workset, rel_tol=tolerance_threshold):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace discard workset is out of "
                    f"acceptable threshold. Iotrace: {iotrace_workset}, "
                    f"fio: {fio_workset}"
                )

        with TestRun.step("Compare discard IOPS"):
            fio_iops = fio_output.trim_iops()
            iotrace_iops = discard_stats.metrics.iops

            if not isclose(iotrace_iops, fio_iops, rel_tol=tolerance_threshold):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace discard iops is out of "
                    f"acceptable threshold. Iotrace: {iotrace_bandwidth}, "
                    f"fio: {fio_bandwidth}"
                )

        with TestRun.step("Compare discard latency"):
            fio_latency_avg = (
                fio_output.trim_completion_latency_average().total_nanoseconds()
            )
            iotrace_latency_avg = discard_stats.latency.average.total_nanoseconds()

            if not isclose(
                iotrace_latency_avg,
                fio_latency_avg,
                abs_tol=latency_tolerance_threshold,
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace discard avarage latency is out of "
                    f"acceptable threshold. Iotrace: {iotrace_latency_avg}, "
                    f"fio: {fio_latency_avg}"
                )

            fio_latency_min = (
                fio_output.trim_completion_latency_min().total_nanoseconds()
            )
            iotrace_latency_min = discard_stats.latency.min.total_nanoseconds()

            if not isclose(
                iotrace_latency_min,
                fio_latency_min,
                abs_tol=latency_tolerance_threshold,
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace discard min latency is out of "
                    f"acceptable threshold. Iotrace: {iotrace_latency_min}, "
                    f"fio: {fio_latency_min}"
                )

            fio_latency_max = (
                fio_output.trim_completion_latency_max().total_nanoseconds()
            )
            iotrace_latency_max = discard_stats.latency.max.total_nanoseconds()

            if not isclose(
                iotrace_latency_max,
                fio_latency_max,
                abs_tol=latency_tolerance_threshold,
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace discard max latency is out of "
                    f"acceptable threshold. Iotrace: {iotrace_latency_max}, "
                    f"fio: {fio_latency_max}"
                )

        with TestRun.step("Compare discard latency percentiles"):
            fio_percentiles = fio_output.trim_completion_latency_percentile()
            iotrace_percentiles = discard_stats.latency.percentiles
            fio_90 = fio_percentiles["90.000000"]
            fio_99 = fio_percentiles["99.000000"]
            fio_99_9 = fio_percentiles["99.900000"]
            fio_99_99 = fio_percentiles["99.990000"]

            if not isclose(
                iotrace_percentiles.le90, fio_90, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace discard 90 percentile is out of "
                    f"acceptable threshold. Iotrace: {iotrace_percentiles.le90}, "
                    f"fio: {fio_90}"
                )
            if not isclose(
                iotrace_percentiles.le99, fio_99, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace discard 99 percentile is out of "
                    f"acceptable threshold. Iotrace: {iotrace_percentiles.le99}, "
                    f"fio: {fio_99}"
                )
            if not isclose(
                iotrace_percentiles.le99_90, fio_99_9, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace discard 99.9 percentile is out of "
                    f"acceptable threshold. Iotrace: {iotrace_percentiles.le99_90}, "
                    f"fio: {fio_99_9}"
                )
            if not isclose(
                iotrace_percentiles.le99_99, fio_99_99, rel_tol=tolerance_threshold
            ):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace discard 99.99 percentile is out of "
                    f"acceptable threshold. Iotrace: {iotrace_percentiles.le99_99}, "
                    f"fio: {fio_99_99}"
                )

        with TestRun.step("Compare number of errors"):
            fio_errors = fio_output.total_errors()
            iotrace_errors = discard_stats.errors

            if not isclose(iotrace_errors, fio_errors, rel_tol=tolerance_threshold):
                TestRun.LOGGER.error(
                    "Difference between fio and iotrace errors is out of "
                    f"acceptable threshold. Iotrace: {iotrace_errors}, "
                    f"fio: {fio_errors}"
                )

    Udev.enable()


def get_fio_cmd(dev):
    fio = (
        Fio()
        .create_command()
        .target(dev.system_path)
        .io_engine(IoEngine.sync)
        .size(Size(1, Unit.GibiByte))
        .block_size(Size(1, Unit.Blocks4096))
        .io_depth(32)
        .num_jobs(1)
        .direct(1)
        .lat_percentiles(True)
        .slat_percentiles(False)
        .clat_percentiles(False)
        .percentile_list(["90.0", "99.0", "99.9", "99.99"])
    )
    return fio
